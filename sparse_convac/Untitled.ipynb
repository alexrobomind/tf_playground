{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.data\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse_convolution as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 10.05.2015 - 18.33.10.02.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.00.15.02.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.01.46.03.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.52.04.04.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.52.04.04_1.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.52.04.04_2.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 15.52.04.04_3.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 20.43.15.05.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 20.43.15.05_1.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 21.17.00.06.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 21.17.00.06_1.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 21.17.00.06_2.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 23.54.18.07.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 23.54.18.07_1.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.28 - 23.54.18.07_2.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.30 - 00.43.38.01.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.30 - 00.43.38.01_1.mp4', 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends\\\\League of Legends 2019.04.30 - 00.43.38.01_2.mp4']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filedir = 'D:\\\\Daten\\\\Videos\\\\Shadowplay\\\\League of Legends';\n",
    "filenames = [filedir + '\\\\' + f for f in os.listdir(filedir)];\n",
    "\n",
    "print(filenames);\n",
    "n_frames = 20;\n",
    "\n",
    "def gen_vid(filename):\n",
    "    filename = filename.decode('utf-8');\n",
    "    vid = cv2.VideoCapture(filename);\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = vid.read();\n",
    "        \n",
    "        if not ret:\n",
    "            break;\n",
    "        \n",
    "        # For whatever reason, OpenCV uses the BGR format\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB);\n",
    "        \n",
    "        yield frame;\n",
    "\n",
    "def gen_vids():\n",
    "    for filename in filenames:\n",
    "        for frame in gen_vid(filename):\n",
    "            yield frame;\n",
    "\n",
    "def data():\n",
    "    with tf.device('device:CPU:0'):\n",
    "        def open_video_dataset(filename):\n",
    "            tf.print('Opening: ');\n",
    "            tf.print(filename);\n",
    "            \n",
    "            return tf.data.Dataset.from_generator(\n",
    "                gen_vid,\n",
    "                tf.uint8,\n",
    "                args = [filename]\n",
    "            );\n",
    "\n",
    "        data = tf.data.Dataset.from_tensor_slices(filenames);\n",
    "        data = data.shuffle(len(filenames));\n",
    "        data = data.repeat();\n",
    "        data = data.interleave(\n",
    "            open_video_dataset,\n",
    "            cycle_length = 8,\n",
    "            block_length = 1,\n",
    "            num_parallel_calls = tf.data.experimental.AUTOTUNE\n",
    "        );\n",
    "\n",
    "        #data = data.repeat();\n",
    "        data = data.shuffle(100);\n",
    "        data = data.map(lambda x : tf.cast(x, tf.float32) / 255);\n",
    "        data = data.padded_batch(3, [1080, 1920, 3]);\n",
    "        data = data.prefetch(5);\n",
    "\n",
    "        return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = lambda x : tf.keras.activations.relu(x, alpha = 1e-2);\n",
    "\n",
    "# Image is 1920 * 1080 *   3   = 6220800\n",
    "test1 = sc.RandomSparseConv2D(   20,   1,  3, 20, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  960 *  540 *  15   = 7776000\n",
    "test2 = sc.RandomSparseConv2D(   40,   1, 20, 40, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  480 *  270 *  30   = 3888000\n",
    "test3 = sc.RandomSparseConv2D(  100,   4, 20, 40, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  240 *  135 *  90   = 1944000\n",
    "test4 = sc.RandomSparseConv2D(  500,  50,  5, 30, kernel_size = (6, 6), strides = (3, 3), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   60 *   27 * 450   =  729000\n",
    "test5 = sc.RandomSparseConv2D( 2000, 100,  5, 40, kernel_size = (6, 8), strides = (3, 4), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   30 *    9 *1000   =  270000\n",
    "test6 = sc.RandomSparseConv2D( 5000, 100, 20,100, kernel_size = (6, 8), strides = (3, 4), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   6  *    3 *3000   =   54000\n",
    "test7 = sc.RandomSparseConv2D(20000, 100, 50,400, kernel_size = (5, 5), strides = (5, 5), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   1  *    1 * 20000 =   20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = lambda x : tf.keras.activations.relu(x, alpha = 1e-2);\n",
    "\n",
    "# Image is 1920 * 1080 *   3   = 6220800\n",
    "test1 = sc.RandomSparseConv2D(   20,   1,  3, 20, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  960 *  540 *  15   = 7776000\n",
    "test2 = sc.RandomSparseConv2D(   40,   1, 20, 40, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  480 *  270 *  30   = 3888000\n",
    "test3 = sc.RandomSparseConv2D(  100,   4, 20, 40, kernel_size = (4, 4), strides = (2, 2), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is  240 *  135 *  90   = 1944000\n",
    "test4 = sc.RandomSparseConv2D(  500,  50,  5, 30, kernel_size = (6, 6), strides = (3, 3), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   60 *   27 * 450   =  729000\n",
    "test5 = sc.RandomSparseConv2D( 2000,  50, 10, 40, kernel_size = (6, 8), strides = (3, 4), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   30 *    9 *1000   =  270000\n",
    "test6 = sc.RandomSparseConv2D( 5000,  50, 20,100, kernel_size = (6, 8), strides = (3, 4), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   6  *    3 *3000   =   54000\n",
    "test7 = sc.RandomSparseConv2D(20000,  50, 50,400, kernel_size = (5, 5), strides = (5, 5), use_bias = True, activation = act, padding = 'same');\n",
    "# Image is   1  *    1 * 20000 =   20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [\n",
    "    test1, test2, test3, test4, test5, test6, test7\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrange = [0, 1, 2, 3, 4, 5, 6, 7];\n",
    "#steps = [200, 200, 200, 200, 200, 200, 200, 200];\n",
    "\n",
    "mrange = [0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 4];\n",
    "steps = [500] * 14;\n",
    "\n",
    "n_tot = len(mrange);\n",
    "\n",
    "models = [sc.EncoderDecoderStack(encoders[0:i+1]) for i in mrange];\n",
    "#weights = [0.5 ** i for i in mrange];\n",
    "#weights = tf.reshape(weights, shape = [n_tot, 1, 1, 1]); # Notice here that the last axis is missing, because loss weights do not use the last dimension\n",
    "#\n",
    "#class MergedModel(tf.keras.Model):\n",
    "#    def __init__(self, models, axis = 0):\n",
    "#        super().__init__();\n",
    "#        \n",
    "#        self.models = models;\n",
    "#        self.axis = 0;\n",
    "#    \n",
    "#    @tf.function\n",
    "#    def call(self, input):\n",
    "#        n = len(self.models);\n",
    "#        #inputs = tf.unstack(input, axis = self.axis, num = n);\n",
    "#        \n",
    "#        outputs = [models[i](input) for i in range(0, n)];\n",
    "#        \n",
    "#        return tf.stack(outputs, axis = self.axis);\n",
    "\n",
    "#model = MergedModel(models);\n",
    "\n",
    "#@tf.function\n",
    "#def loss_fn(x, y):\n",
    "#    return tf.keras.losses.MeanSquaredError()(x, y, weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adadelta(1.0);\n",
    "\n",
    "for model in models:\n",
    "    model.compile(optimizer = optimizer, loss = 'mse');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 0\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.01.46.03.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 10.05.2015 - 18.33.10.02.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 20.43.15.05_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.00.15.02.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_3.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 20.43.15.05.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.01.46.03.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 20.43.15.05.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 20.43.15.05_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 10.05.2015 - 18.33.10.02.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 20.43.15.05.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.01.46.03.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 23.54.18.07_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.00.15.02.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_3.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.30 - 00.43.38.01_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_1.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.52.04.04_2.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 15.00.15.02.mp4\n",
      "Opening: \n",
      "D:\\Daten\\Videos\\Shadowplay\\League of Legends\\League of Legends 2019.04.28 - 21.17.00.06_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0908 13:23:13.795098  8696 callbacks.py:243] Method (on_train_batch_end) is slow compared to the batch update (34.878995). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      1/Unknown - 39s 39s/step - loss: 0.0616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0908 13:23:24.967737  8696 callbacks.py:243] Method (on_train_batch_end) is slow compared to the batch update (20.062648). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      2/Unknown - 50s 25s/step - loss: 0.0555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0908 13:23:25.584772  8696 callbacks.py:243] Method (on_train_batch_end) is slow compared to the batch update (5.246300). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      3/Unknown - 51s 17s/step - loss: 0.0480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0908 13:23:26.314814  8696 callbacks.py:243] Method (on_train_batch_end) is slow compared to the batch update (2.715155). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    468/Unknown - 328s 700ms/step - loss: 0.0025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-bb2e041830dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mupdate_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             ),\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mBatchImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         ]\n\u001b[0;32m     55\u001b[0m     );\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1301\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    977\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    978\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    980\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    981\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reduction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m           \u001b[0mper_sample_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m           weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[0;32m    168\u001b[0m               \u001b[0mper_sample_losses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    764\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m   \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programme\\python 3.6.6\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msquared_difference\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  10994\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m  10995\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10996\u001b[1;33m         \"SquaredDifference\", name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m  10997\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10998\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, n_tot):\n",
    "    print('Processing model {}'.format(i));\n",
    "    model = models[i];\n",
    "\n",
    "    ds = data().take(steps[i]);\n",
    "\n",
    "    def map_fn(x):\n",
    "        #x2 = tf.expand_dims(x, axis = 0);\n",
    "        #x2 = tf.tile(x2, [n_tot, 1, 1, 1, 1]);\n",
    "\n",
    "        return (x, x);\n",
    "\n",
    "    ds = ds.map(map_fn);\n",
    "\n",
    "    summary_source = data().__iter__();\n",
    "\n",
    "    class BatchImage(tf.keras.callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__();\n",
    "\n",
    "        def on_train_batch_end(self, batch, logs={}):\n",
    "            if batch % 100 != 0:\n",
    "                return;\n",
    "\n",
    "            writer = tf.summary.create_file_writer('./logs/train');\n",
    "\n",
    "            sample = next(summary_source);\n",
    "\n",
    "            with writer.as_default():\n",
    "                tf.summary.image(\n",
    "                    'Input',\n",
    "                    sample,\n",
    "                    step = batch\n",
    "                );\n",
    "\n",
    "                #for i in range(0, n_tot):\n",
    "                sample_fb = model.decoder(model.encoder(sample));\n",
    "\n",
    "                tf.summary.image(\n",
    "                    'Output',\n",
    "                    sample_fb,\n",
    "                    step = batch\n",
    "                );\n",
    "\n",
    "    model.fit_generator(\n",
    "        ds,\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                'logs',\n",
    "                write_graph = True,\n",
    "                update_freq = 10\n",
    "            ),\n",
    "            BatchImage()\n",
    "        ]\n",
    "    );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[-1].save_weights(\"weights\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[-1].load_weights(\"weights\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
