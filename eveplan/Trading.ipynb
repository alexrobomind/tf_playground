{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "import matplotlib\n",
    "import itertools\n",
    "\n",
    "import esipy as esi\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Currently, memory growth needs to be the same across GPUs\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:    \n",
    "    def __enter__(self):\n",
    "        self.start = time.clock()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.clock()\n",
    "        self.interval = self.end - self.start\n",
    "        \n",
    "        print(self.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defining a 'User-Agent' header is a good practice, and allows CCP to contact you if required. To do this, simply add the following when creating the client: headers={'User-Agent':'something'}.\n",
      "d:\\programme\\python 3.6.6\\lib\\site-packages\\esipy\\client.py:82: UserWarning: Defining a 'User-Agent' header is a good practice, and allows CCP to contact you if required. To do this, simply add the following when creating the client: headers={'User-Agent':'something'}.\n",
      "  warnings.warn(warning_message)\n"
     ]
    }
   ],
   "source": [
    "# Set up network access\n",
    "esi_client = esi.EsiClient(\n",
    "    transport_adapter = requests.adapters.HTTPAdapter(\n",
    "        pool_connections=100,\n",
    "        pool_maxsize=100,\n",
    "        max_retries=10,\n",
    "        pool_block=False\n",
    "    )\n",
    ")\n",
    "esi_app    = esi.EsiApp()\n",
    "\n",
    "app = esi_app.get_latest_swagger\n",
    "\n",
    "def try_request(req):\n",
    "    while True:\n",
    "        response = esi_client.request(req)\n",
    "        \n",
    "        if response.status == 200:\n",
    "            return response.data\n",
    "        \n",
    "        print(response.status)\n",
    "        print(response.header)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading constellation data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b81084fa5f04eeb92fbe7b38107fc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1146.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def intd(f):\n",
    "    return {int(k) : v for k,v in json.load(f).items()};\n",
    "\n",
    "with open('universe/systems.txt') as f:\n",
    "    systems = intd(f);\n",
    "\n",
    "with open('universe/stargates.txt') as f:\n",
    "    stargates = intd(f);\n",
    "    \n",
    "with open('universe/market_types.txt') as f:\n",
    "    types = intd(f)\n",
    "\n",
    "print('Loading constellation data ...')\n",
    "constellation_ids = esi_client.request(\n",
    "    app.op['get_universe_constellations']()\n",
    ").data\n",
    "\n",
    "constellations = {\n",
    "    i : try_request(app.op['get_universe_constellations_constellation_id'](constellation_id = i))\n",
    "    for i in tqdm(constellation_ids)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972\n"
     ]
    }
   ],
   "source": [
    "systems_graph = nx.Graph();\n",
    "\n",
    "for system in systems:\n",
    "    systems_graph.add_node(system);\n",
    "\n",
    "for stargate in stargates.values():\n",
    "    systems_graph.add_edge(stargate[\"system_id\"], stargate[\"destination\"][\"system_id\"])\n",
    "\n",
    "root = 'Jita'\n",
    "root_id = [v for v in systems if systems[v][\"name\"] == root][0]\n",
    "\n",
    "# Limit to high-sec systems\n",
    "subselect = [k for k in systems if systems[k][\"security_status\"] >= 0.5]\n",
    "subgraph = systems_graph.subgraph(subselect)\n",
    "\n",
    "# Limit to component connected to Jita\n",
    "subselect = nx.node_connected_component(subgraph, root_id)\n",
    "subgraph = systems_graph.subgraph(subselect)\n",
    "print(len(subgraph))\n",
    "\n",
    "system_ids = list(subgraph)\n",
    "type_ids = list(types)\n",
    "\n",
    "landmark_names = ['Jita', 'Amarr', 'Rens', 'Hek', 'Dodixie', 'Oursulaert', 'Tash-Murkon Prime', 'Agil'];\n",
    "landmarks = [v[\"system_id\"] for v in systems.values() if v[\"name\"] in landmark_names]\n",
    "\n",
    "# Compute pair-wise distances\n",
    "distances = dict(nx.shortest_path_length(subgraph))\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def system_distance(s1, s2):\n",
    "    #return nx.shortest_path_length(subgraph, s1, s2)\n",
    "    return distances[s1][s2]\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def get_region_id(system_id):\n",
    "    return constellations[systems[system_id][\"constellation_id\"]].region_id\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def get_station(station_id):\n",
    "    esi_op = app.op['get_universe_stations_station_id'](station_id = station_id);\n",
    "    return esi_client.request(esi_op).data\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def in_highsec(station_id):\n",
    "    try:\n",
    "        return get_station(station_id).system_id in subgraph\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading regions\n",
      "Loading market orders\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd5c4a2ff9b45a3993c4be964ed40a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Regions', max=20.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading orders in Sinq Laison\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0ea8171e36451b9f185f7d7f175a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=105.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[https://esi.evetech.net/latest/markets/10000032/orders/?datasource=tranquility&order_type=all&page=43] returned expired result: {'Date': 'Mon, 24 Feb 2020 10:06:06 GMT', 'Content-Type': 'application/json; charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Headers': 'Content-Type,Authorization,If-None-Match,X-User-Agent', 'Access-Control-Allow-Methods': 'GET,HEAD,OPTIONS', 'Access-Control-Allow-Origin': '*', 'Access-Control-Expose-Headers': 'Content-Type,Warning,ETag,X-Pages,X-ESI-Error-Limit-Remain,X-ESI-Error-Limit-Reset', 'Access-Control-Max-Age': '600', 'Allow': 'GET,HEAD,OPTIONS', 'Cache-Control': 'public', 'Content-Encoding': 'gzip', 'Etag': '\"9e85997e79e1103337acdb9a991fcafe28803ed7bab124f773482520\"', 'Expires': 'Mon, 24 Feb 2020 10:06:06 GMT', 'Last-Modified': 'Mon, 24 Feb 2020 10:01:06 GMT', 'Strict-Transport-Security': 'max-age=31536000', 'Vary': 'Accept-Encoding', 'X-Esi-Error-Limit-Remain': '100', 'X-Esi-Error-Limit-Reset': '54', 'X-Esi-Request-Id': 'bd5999a2-f3c0-4499-a3a7-d5a19e1f8d06', 'X-Pages': '105'}\n",
      "d:\\programme\\python 3.6.6\\lib\\site-packages\\esipy\\client.py:332: UserWarning: [https://esi.evetech.net/latest/markets/10000032/orders/?datasource=tranquility&order_type=all&page=43] returned expired result\n",
      "  warnings.warn(\"[%s] returned expired result\" % res.url)\n",
      "[https://esi.evetech.net/latest/markets/10000032/orders/?datasource=tranquility&order_type=all&page=44] returned expired result: {'Date': 'Mon, 24 Feb 2020 10:06:07 GMT', 'Content-Type': 'application/json; charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Headers': 'Content-Type,Authorization,If-None-Match,X-User-Agent', 'Access-Control-Allow-Methods': 'GET,HEAD,OPTIONS', 'Access-Control-Allow-Origin': '*', 'Access-Control-Expose-Headers': 'Content-Type,Warning,ETag,X-Pages,X-ESI-Error-Limit-Remain,X-ESI-Error-Limit-Reset', 'Access-Control-Max-Age': '600', 'Allow': 'GET,HEAD,OPTIONS', 'Cache-Control': 'public', 'Content-Encoding': 'gzip', 'Etag': '\"f2813c1e0fea8c6b30b028459555abffb87e973d88715fc8ccce17aa\"', 'Expires': 'Mon, 24 Feb 2020 10:06:07 GMT', 'Last-Modified': 'Mon, 24 Feb 2020 10:01:06 GMT', 'Strict-Transport-Security': 'max-age=31536000', 'Vary': 'Accept-Encoding', 'X-Esi-Error-Limit-Remain': '100', 'X-Esi-Error-Limit-Reset': '53', 'X-Esi-Request-Id': '962b9fc0-d672-4fe1-b4cb-43c1fedb2da9', 'X-Pages': '105'}\n",
      "d:\\programme\\python 3.6.6\\lib\\site-packages\\esipy\\client.py:332: UserWarning: [https://esi.evetech.net/latest/markets/10000032/orders/?datasource=tranquility&order_type=all&page=44] returned expired result\n",
      "  warnings.warn(\"[%s] returned expired result\" % res.url)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in The Citadel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306ea9c52910425da8725569aafec99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=53.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in The Forge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7525b2617349e28486dbdbad4225b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=294.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Genesis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eefbc05f39482e9ab37b009212910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=31.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Verge Vendor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7f06f4f5e6432aa10a4f98b5796275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=31.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Devoid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9563cb680fd3407b83d31c0676520c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=12.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Kor-Azor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d48eccc704c4f08915210886b1f16a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=20.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Everyshore\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384da755e87440378558bea0c8705a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=24.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Essence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4745c0fe89143a5890e5076ae3b68a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=43.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Derelik\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4084d936354e422dbc67b3e3cd6d2bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=18.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Metropolis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9849e7c494a44e488c486ed182d70550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=101.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "{'Server': ['awselb/2.0'], 'Date': ['Mon, 24 Feb 2020 10:10:25 GMT'], 'Content-Type': ['text/html'], 'Content-Length': ['138'], 'Connection': ['keep-alive']}\n",
      "\n",
      "Loading orders in Domain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac5b0e2ccc348b89ce3fd8af52e7cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=145.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in The Bleak Lands\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c898824c7482186bc460306f89bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=12.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Lonetrek\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b88c63b17742328dfa35638d90a66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=68.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Placid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a2c635d3ee4c199c0b4eb608949d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=38.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Khanid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e42cd87784f4a7a90e3db7f1660244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=8.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Tash-Murkon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43c545e9ae24273878c0af3ed3ac74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=38.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Kador\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efb015d41504c61a4ab4ee2be71cf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=24.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Molden Heath\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4023184238a14eff9ddb35124437b809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=21.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading orders in Heimatar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74597bf4f28d46e986b1fcb347d89a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pages', max=70.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load orders\n",
    "region_id = get_region_id(root_id)\n",
    "\n",
    "print('Loading regions')\n",
    "#region_ids = esi_client.request(app.op['get_universe_regions']()).data\n",
    "region_ids = list(set(\n",
    "    get_region_id(system_id) for system_id in subgraph\n",
    "))\n",
    "\n",
    "print('Loading market orders')\n",
    "\n",
    "def requests_in_region(region_id):\n",
    "    region = esi_client.request(\n",
    "        app.op['get_universe_regions_region_id'](region_id = region_id)\n",
    "    ).data\n",
    "    \n",
    "    print('Loading orders in {}'.format(region.name))\n",
    "    n_pages = esi_client.request(\n",
    "        app.op['get_markets_region_id_orders'](region_id = region_id)\n",
    "    ).header['X-pages'][0]\n",
    "\n",
    "    p = mp.pool.ThreadPool(1)\n",
    "\n",
    "    requests = [\n",
    "        app.op['get_markets_region_id_orders'](region_id = region_id, page = page)\n",
    "        for page in range(1, n_pages + 1)\n",
    "    ]\n",
    "    \n",
    "    return requests\n",
    "\n",
    "orders = {\n",
    "    region_id : [\n",
    "        order\n",
    "        for request in tqdm(requests_in_region(region_id), desc = 'Pages')\n",
    "        for order in try_request(request)\n",
    "    ]\n",
    "    for region_id in tqdm(region_ids, desc = 'Regions')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structure of the state space\n",
    "class StateProp:\n",
    "    def __init__(self, default, convert = (lambda x: x, lambda x: x)):\n",
    "        self.convert_in = convert[0]\n",
    "        self.convert_out = convert[1]\n",
    "        self.default = default\n",
    "\n",
    "def to_fixed(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    return State(x)\n",
    "\n",
    "def to_mutable(x):\n",
    "    if x is None:\n",
    "        return none\n",
    "    return MutableState(x)\n",
    "\n",
    "state_props = {\n",
    "    # Position of the ship\n",
    "    'system' : StateProp(0),\n",
    "    'station' : StateProp(None),\n",
    "    \n",
    "    # Configuration of the ship\n",
    "    'volume_limit' : StateProp(0),\n",
    "    'collateral_limit' : StateProp(0),\n",
    "    \n",
    "    # Resource balance\n",
    "    'time_left' : StateProp(0),\n",
    "    'wallet' : StateProp(0),\n",
    "    'cargo' : StateProp((), (tuple, list)),\n",
    "    \n",
    "    # Market cursors\n",
    "    'market_group' : StateProp(None),\n",
    "    'market_item' : StateProp(None),\n",
    "    'last_modified_item' : StateProp(None)\n",
    "}\n",
    "    \n",
    "# Implementation of the state space\n",
    "class State:\n",
    "    def __init__(self, inp):\n",
    "        for name, prop in state_props.items():\n",
    "            inval = getattr(inp, name, prop.default)\n",
    "            inval = prop.convert_in(inval)\n",
    "            object.__setattr__(self, '_prop_' + name, inval)\n",
    "            \n",
    "        self._encode_cache = None\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        if name in state_props:\n",
    "            return getattr(self, '_prop_' + name)\n",
    "        else:\n",
    "            raise AttributeError\n",
    "    \n",
    "    def __setattr__(self, name, val):\n",
    "        if name in state_props:\n",
    "            raise AttributeError('Attribute {} is immutable'.format(name))\n",
    "        \n",
    "        object.__setattr__(self, name, val)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        h = 0\n",
    "        \n",
    "        for name in state_props:\n",
    "            h = h ^ hash(getattr(self, name))\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        for name in state_props:\n",
    "            if getattr(self, name) != getattr(other, name):\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        (vleft, cleft) = self.limits_left()\n",
    "        vmax = self.volume_limit\n",
    "        cmax = self.collateral_limit\n",
    "        v = vmax - vleft\n",
    "        c = cmax - cleft\n",
    "        \n",
    "        def cinfo(cid):\n",
    "            def locinfo(lid):\n",
    "                if(self.station == lid):\n",
    "                    return \"Here\"\n",
    "                \n",
    "                system = get_station(lid).system_id\n",
    "                if(system == self.system):\n",
    "                    return \"In system\"\n",
    "                \n",
    "                return \"{} jumps\".format(nx.shortest_path_length(subgraph, system, self.system))\n",
    "            \n",
    "            c = contracts[cid]\n",
    "                \n",
    "            return \"{cid} ({l1} -> {l2})\".format(\n",
    "                l1 = locinfo(c.start_location_id),\n",
    "                l2 = locinfo(c.end_location_id),\n",
    "                cid = cid\n",
    "            )\n",
    "        return \"\"\"\n",
    "State:\n",
    "    Time left: {t}\n",
    "    \n",
    "    System:  {system}\n",
    "    Station: {station}\n",
    "    \n",
    "    Collateral: {c} / {cmax} ({cleft} left)\n",
    "    Cargo:      {v} / {vmax} ({vleft} left)\n",
    "    \n",
    "    Value:     {val}\n",
    "        \"\"\".format(\n",
    "            t = self.time_left,\n",
    "            system = self.system,\n",
    "            station = self.station,\n",
    "            c = c, cmax = cmax, cleft = cleft,\n",
    "            v = v, vmax = vmax, vleft = vleft,\n",
    "            val = self.value\n",
    "        )\n",
    "    \n",
    "    def limits_left(self):\n",
    "        total_vol = 0\n",
    "        total_col = 0\n",
    "        \n",
    "        for item, count, avgval in self.cargo:\n",
    "            total_vol += types[item][\"volume\"] * count\n",
    "            total_col += avgval * count\n",
    "        \n",
    "        return (self.volume_limit - total_vol, self.collateral_limit - total_col)\n",
    "    \n",
    "    def validate(self):\n",
    "        (v, c) = self.limits_left()\n",
    "        assert v >= 0, 'Volume exceeded'\n",
    "        assert c >= 0, 'Collateral exceeded'\n",
    "        \n",
    "        assert self.time_left >= 0, 'Out of time'\n",
    "        \n",
    "        # Make sure we don't accept contracts we can't deliver at all\n",
    "        for c in self.accepted:\n",
    "            assert contracts[c].volume <= self.volume_limit, 'Accepted contract {} exceeds total volume'.format(c)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.wallet\n",
    "        \n",
    "\n",
    "# Helper class for incremental state modification\n",
    "class MutableState:\n",
    "    def __init__(self, other = None):\n",
    "        if other is None:\n",
    "            for name, prop in state_props.items():\n",
    "                setattr(self, name, prop.default)\n",
    "        else:\n",
    "            setattr(self, name, prop.convert_out(getattr(name, other)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action calculus on states\n",
    "\n",
    "warp_time = 1.0\n",
    "accept_range = 5\n",
    "\n",
    "max_volume = 1e6\n",
    "\n",
    "# Wrapper that allows an action to just modify a mutable state representation\n",
    "# and performs validity checking of resulting state\n",
    "class ActionImpl:\n",
    "    def __init__(self, f):\n",
    "        self.wrapped = f;\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        s = MutableState(state)\n",
    "        s.last_modified_item = None\n",
    "        f(s)\n",
    "        s = State(s)\n",
    "        \n",
    "        s.validate()\n",
    "        \n",
    "        return s\n",
    "        \n",
    "def action(f):\n",
    "    return ActionImpl(f)\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def warp_to(station_id):\n",
    "    station = get_station(station_id)\n",
    "    \n",
    "    distances = nx.shortest_path_length(subgraph, station.system_id)\n",
    "    \n",
    "    @action\n",
    "    def do_warp_to(s):\n",
    "        assert s.station != station_id, 'Cannot warp from to same station'\n",
    "        \n",
    "        if s.system == station.system_id:\n",
    "            t = warp_time\n",
    "        else:\n",
    "            #t = warp_time * nx.shortest_path_length(subgraph, s.system, station.system_id)\n",
    "            t = warp_time * distances[s.system]\n",
    "        \n",
    "        s.station = station_id\n",
    "        s.system = station.system_id\n",
    "        \n",
    "        s.time_left -= t\n",
    "    \n",
    "    return do_warp_to\n",
    "\n",
    "def actions(s):\n",
    "    (vol, col) = s.limits_left()\n",
    "    \n",
    "    accept_actions = [\n",
    "        accept_contract(c)\n",
    "        for c in contracts.values()\n",
    "        if c.volume <= vol and c.collateral <= col\n",
    "    ]\n",
    "    \n",
    "    #jump_actions = [\n",
    "    #    jump_to_system(sys)\n",
    "    #    for sys in subgraph.neighbors(s.system)\n",
    "    #]\n",
    "    \n",
    "    #dock_actions = [\n",
    "    #    warp_to_station(sta)\n",
    "    #    for sta in systems[s.system].get(\"stations\", [])\n",
    "    #]\n",
    "    \n",
    "    warp_targets = [\n",
    "        contracts[cid].start_location_id\n",
    "        for cid in s.accepted\n",
    "    ] + [\n",
    "        contracts[cid].end_location_id\n",
    "        for cid in s.loaded\n",
    "    ]\n",
    "    \n",
    "    warp_actions = [\n",
    "        warp_to(t)\n",
    "        for t in warp_targets\n",
    "    ]\n",
    "    \n",
    "    load_actions = [\n",
    "        load_contract(contracts[cid])\n",
    "        for cid in s.accepted\n",
    "        if s.station is not None and contracts[cid].start_location_id == s.station\n",
    "    ]\n",
    "    \n",
    "    finish_actions = [\n",
    "        finish_contract(contracts[cid])\n",
    "        for cid in s.loaded\n",
    "        if s.station is not None and contracts[cid].end_location_id == s.station\n",
    "    ]\n",
    "    \n",
    "    result = warp_actions + load_actions + finish_actions + accept_actions\n",
    "    \n",
    "    return result\n",
    "\n",
    "def apply_action(a, s):\n",
    "    try:\n",
    "        return a(s)\n",
    "    except AssertionError as e:\n",
    "        return None\n",
    "\n",
    "def apply_actions(s):\n",
    "    return [\n",
    "        s2\n",
    "        for s2 in [apply_action(a, s) for a in actions(s)]\n",
    "        if s2 is not None\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a node into a state space traversal graph by expanding every node that maximizes a given heuristic\n",
    "def expand(root, heuristic, count, sort_every = 5):\n",
    "    result = nx.DiGraph()\n",
    "    result.add_node(root)\n",
    "    \n",
    "    unexpanded = [root]\n",
    "    \n",
    "    for counter in trange(0, count):\n",
    "        if not unexpanded:\n",
    "            break;\n",
    "        s = unexpanded.pop()\n",
    "        \n",
    "        new_states = apply_actions(s)\n",
    "        \n",
    "        for s2 in new_states:\n",
    "            if s2 not in result:\n",
    "                result.add_node(s2)\n",
    "                #unexpanded.append(s2)\n",
    "                unexpanded.insert(0, s2)\n",
    "            \n",
    "            result.add_edge(s, s2)\n",
    "        \n",
    "        if counter % sort_every == 0:\n",
    "            unexpanded.sort(key = heuristic)\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "    return result, frozenset(unexpanded)\n",
    "\n",
    "def get_values(root, g, unexpanded, heuristic):\n",
    "    values = {}\n",
    "    for node in nx.dfs_postorder_nodes(g, root):\n",
    "        # Unexpanded nodes are weighted with their heuristic\n",
    "        if node in unexpanded:\n",
    "            values[node] = heuristic(node)\n",
    "            continue\n",
    "        \n",
    "        # Expanded nodes are weighted with the maximum of successor nodes\n",
    "        # and the known value of the node\n",
    "        val = node.value()\n",
    "        for n2 in g.successors(node):\n",
    "            if n2 not in values:\n",
    "                continue\n",
    "                \n",
    "            val = max(val, values[n2])\n",
    "        \n",
    "        values[node] = val\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layers\n",
    "\n",
    "def full_attention(keys, values, queries):\n",
    "    \"\"\"\n",
    "        keys    - batch_shape + [n_sequence1, dim_k] tensor holding query keys\n",
    "        values  - batch_shape + [n_sequence1, dim_v] tensor holding query results\n",
    "        queries - batch_shape + [n_sequence2, dim_k] tensor holding queries\n",
    "\n",
    "        Returns batch_shape + [n_sequence2, dim_v] tensor holding result\n",
    "    \"\"\"\n",
    "    with tf.name_scope('scaled_dot_product_attention'):\n",
    "        # Compute the [..., n_sequence2, n_sequence1] matrix of weights\n",
    "        weights = tf.linalg.matmul(queries, keys, transpose_b = True)\n",
    "        \n",
    "        # Normalize against the key dimension\n",
    "        dk = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "        weights = weights / tf.math.sqrt(dk)\n",
    "        \n",
    "        # Compute softmax over the sequence1 dimension\n",
    "        weights = tf.nn.softmax(weights, axis = -1)\n",
    "        \n",
    "        # Apply weights to values\n",
    "        result = tf.linalg.matmul(weights, values)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "def reduced_attention(keys, values, queries):\n",
    "    \"\"\"\n",
    "        keys    - batch_shape + [n_sequence1, dim_k] tensor holding query keys\n",
    "        values  - batch_shape + [n_sequence1, dim_v] tensor holding query results\n",
    "        queries - batch_shape + [n_sequence2, dim_k] tensor holding queries\n",
    "\n",
    "        Returns batch_shape + [n_sequence2, dim_v] tensor holding result\n",
    "    \"\"\"\n",
    "    with tf.name_scope('reduced_scaled_dot_product_attention'):\n",
    "        # Compute the [..., dim_k, dim_v] matrix of weights\n",
    "        weights = tf.linalg.matmul(keys, values, transpose_a = True)\n",
    "        \n",
    "        # Normalize against the key dimension\n",
    "        dk = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "        weights = weights / tf.math.sqrt(dk)\n",
    "        \n",
    "        # Compute softmax over the dim_k dimension\n",
    "        weights = tf.nn.softmax(weights, axis = -2)\n",
    "        \n",
    "        # Apply weights to values\n",
    "        result = tf.linalg.matmul(queries, weights)\n",
    "        \n",
    "        return result\n",
    "\n",
    "class MultiHeadedAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_out, d_model, num_heads, f = reduced_attention):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "    \n",
    "        self.wk = tf.keras.layers.Dense(num_heads * d_model, name = 'Wk')\n",
    "        self.wv = tf.keras.layers.Dense(num_heads * d_model, name = 'Wv')\n",
    "        self.wq = tf.keras.layers.Dense(num_heads * d_model, name = 'Wq')\n",
    "        \n",
    "        self.wout = tf.keras.layers.Dense(d_out, name = 'Wout')\n",
    "        \n",
    "        self.f = f\n",
    "        \n",
    "    def _split_heads(self, x):\n",
    "        with tf.name_scope('split_heads'):\n",
    "            # Ensure static shape\n",
    "            #x.set_shape(tf.TensorShape([None, None, num_heads * d_model]))\n",
    "            #static_shape = x.get_shape();\n",
    "\n",
    "            # Dynamic reshape\n",
    "            batch_size = tf.shape(x)[0]\n",
    "            seq_len = tf.shape(x)[1]\n",
    "\n",
    "            x = tf.reshape(x, [batch_size, seq_len, self.num_heads, self.d_model])\n",
    "\n",
    "            # Static reshape\n",
    "            # x.set_shape(static_shape[0:2] + tf.TensorShape([num_heads, d_model]))\n",
    "\n",
    "            x = tf.transpose(x, [0, 2, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def _merge_heads(self, x):\n",
    "        with tf.name_scope('merge_heads'):\n",
    "            batch_size = tf.shape(x)[0]\n",
    "            seq_len    = tf.shape(x)[2]\n",
    "\n",
    "            x = tf.transpose(x, [0, 2, 1, 3])\n",
    "            x = tf.reshape(x, [batch_size, seq_len, self.num_heads * self.d_model])\n",
    "            return x\n",
    "        \n",
    "    def call(self, k, v = None, q = None):\n",
    "        if v == None:\n",
    "            v = k\n",
    "        \n",
    "        if q == None:\n",
    "            q = k\n",
    "\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        q = self.wq(q)\n",
    "        \n",
    "        k = self._split_heads(k)\n",
    "        v = self._split_heads(v)\n",
    "        q = self._split_heads(q)\n",
    "        \n",
    "        result = self.f(k, v, q)\n",
    "        result = self._merge_heads(result)\n",
    "        \n",
    "        return self.wout(result)\n",
    "    \n",
    "# ------------------ Model class -----------------------------------------\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, n_layers, output_width = 128, n_heads = 16, head_dimension = 8):\n",
    "        super(Model, self).__init__()\n",
    "        self.ratt_layers = [\n",
    "            MultiHeadedAttention(output_width, n_heads, head_dimension)\n",
    "            for i in range(0, n_layers)\n",
    "        ]\n",
    "        \n",
    "        self.type_data = tf.Variable(np.zeros([len(types), 10], dtype = np.float32))\n",
    "        self.system_data = tf.Variable(np.zeros([len(subgraph), 10]), dtype = np.float32)\n",
    "        \n",
    "    # Args:\n",
    "    #  orders: Tuple of 2 [None, None] ragged tensors describing types and systems of orders\n",
    "    #          and one [None, None, n_order_data] ragged tensor giving static data for the market orders\n",
    "    def call(self, orders):\n",
    "        def apply_nobatch(layer, x):\n",
    "            x = tf.expand_dims(x, axis = 0)\n",
    "            x = layer(x)\n",
    "            x = tf.squeeze(x, axis = 0)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        # Unpack orders and apply static data for systems, merge results into input\n",
    "        (order_types, order_systems, order_data) = orders\n",
    "        \n",
    "        def ragged_gather(values, keys):\n",
    "            return keys.with_flat_values(\n",
    "                tf.gather(keys.flat_values, values)\n",
    "            )\n",
    "        \n",
    "        print(self.type_data.shape)\n",
    "        print(order_types.shape)\n",
    "        print(tf.gather(self.type_data, order_types).shape)\n",
    "        \n",
    "        v = tf.concat([\n",
    "                tf.gather(self.type_data, order_types),\n",
    "                tf.gather(self.system_data, order_systems),\n",
    "                order_data\n",
    "            ],\n",
    "            axis = -1\n",
    "        )\n",
    "        \n",
    "        # Apply layers to input\n",
    "        for layer in self.ratt_layers:\n",
    "            with tf.name_scope('apply_nobatch'):\n",
    "                v = tf.ragged.map_flat_values(\n",
    "                    lambda x: apply_nobatch(layer, x),\n",
    "                    v\n",
    "                )\n",
    "            \n",
    "        return v     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping orders by type\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002416708fbf46f39b7b9af46b94feba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flattening data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa530626494475095905d08c1b1e407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing sizes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c9971321fe4103957252f91fb4f032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=289320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sending data to GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521f5e5bfbb9446e98d8f5b105874cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f7993687bc4020aee9723826e05577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Solar system encoding\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def encode_system(system_id):\n",
    "    if system_id not in system_ids:\n",
    "        return None\n",
    "    \n",
    "    index = system_ids.index(system_id)\n",
    "    system = systems[system_id]\n",
    "    \n",
    "    return index, [system[\"security_status\"]] + [system_distance(l, system_id) for l in landmarks]\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def encode_type(type_id):\n",
    "    if type_id not in type_ids:\n",
    "        return None\n",
    "    \n",
    "    index = type_ids.index(type_id)\n",
    "    t = types[type_id]\n",
    "    \n",
    "    return index, [\n",
    "        t[\"volume\"]\n",
    "    ]    \n",
    "\n",
    "# Encoding of an order\n",
    "def encode_order(order):\n",
    "    try:\n",
    "        tindex, tdata = encode_type(order.type_id)\n",
    "        sindex, sdata = encode_system(order.system_id)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return tindex, sindex, tdata + sdata + [\n",
    "        order.location_id,\n",
    "        order.volume_remain,\n",
    "        1 if order.is_buy_order else 0,\n",
    "        0 if order.is_buy_order else 1\n",
    "    ]\n",
    "\n",
    "def encode_orders(orders):\n",
    "    print('Grouping orders by type')\n",
    "    orders_by_type = {\n",
    "        region_id : {\n",
    "            type_id : [encode_order(o) for o in os]\n",
    "            for (type_id, os) in itertools.groupby(orders[region_id], lambda x: x.type_id)\n",
    "        }\n",
    "        for region_id in tqdm(region_ids)\n",
    "    }\n",
    "    \n",
    "    print('Flattening data')\n",
    "    almost_flat_data = [\n",
    "        [\n",
    "            [o[i] for o in orders_by_type[region_id].get(type_id, []) if o is not None]\n",
    "            for region_id in region_ids\n",
    "            for type_id in types\n",
    "        ]\n",
    "        for i in tqdm(range(0, 3))\n",
    "    ]\n",
    "    \n",
    "    print('Computing sizes')\n",
    "    lengths_dim2 = tf.constant([\n",
    "            len(a)\n",
    "            for a in tqdm(almost_flat_data[0])\n",
    "        ], dtype = tf.int32\n",
    "    )\n",
    "    \n",
    "    print('Sending data to GPU')\n",
    "    flat_data = [\n",
    "        tf.constant([\n",
    "            aaa\n",
    "            for aa in almost_flat_data[i]\n",
    "            for aaa in aa\n",
    "        ], dtype = tf.float32 if i == 2 else tf.int32)\n",
    "        for i in trange(0, len(almost_flat_data))\n",
    "    ]\n",
    "    \n",
    "    result = [\n",
    "        tf.RaggedTensor.from_uniform_row_length(\n",
    "            tf.RaggedTensor.from_uniform_row_length(\n",
    "                tf.RaggedTensor.from_row_lengths(\n",
    "                    flat_data[i],\n",
    "                    lengths_dim2\n",
    "                ),\n",
    "                len(types)\n",
    "            ),\n",
    "            len(region_ids)\n",
    "        )\n",
    "        for i in tqdm(range(0, 3))\n",
    "    ]\n",
    "    \n",
    "    return tuple(result)\n",
    "\n",
    "encoded_orders = encode_orders(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14466, 10)\n",
      "(1, None, None, None)\n",
      "(1, None, None, None, 10)\n",
      "(14466, 10)\n",
      "(1, None, None, None)\n",
      "(1, None, None, None, 10)\n"
     ]
    }
   ],
   "source": [
    "m = Model(3)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    y = m(x)\n",
    "    return y\n",
    "\n",
    "import datetime\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = 'logs/func'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "# Call only one tf.function when tracing.\n",
    "z = f(encoded_orders)\n",
    "\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"my_func_trace_2\",\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf.ragged.constant([[[0]], [[2], [3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = MutableState()\n",
    "\n",
    "s.system = root_id\n",
    "s.time_left = 40.0\n",
    "\n",
    "ship = 'tayra'\n",
    "\n",
    "if ship == 'charon':\n",
    "    s.volume_limit = 1350000\n",
    "    s.collateral_limit = 750000000\n",
    "elif ship == 'tayra':\n",
    "    s.volume_limit = 8395\n",
    "    s.collateral_limit = 100000000\n",
    "\n",
    "expanded = set([])\n",
    "\n",
    "def heur(x):\n",
    "    return x.value()\n",
    "\n",
    "g, unexp = expand(State(s), heur, 30000)\n",
    "\n",
    "heurmax = max(*[heur(n) for n in g])\n",
    "print(heurmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run(\"expand(State(s), heur, 10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cycles = nx.simple_cycles(g);\n",
    "\n",
    "for c in cycles:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "nx.draw_networkx(\n",
    "    g,\n",
    "    labels = {n:systems[n.system][\"name\"] for n in g},\n",
    "    node_size = [300 * heur(n) / heurmax for n in g],\n",
    "    node_color = [heur(n) / heurmax for n in g],\n",
    "    cmap = 'jet'\n",
    ")\n",
    "\n",
    "c = matplotlib.colorbar.ColorbarBase(plt.gca(), cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = get_values(State(s), g, unexp, heur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "valmax = max(*vals.values())\n",
    "\n",
    "subg = g.subgraph([n for n in g if vals[n] == valmax])\n",
    "\n",
    "nx.draw_networkx(\n",
    "    subg,\n",
    "    labels = {n:systems[n.system][\"name\"] for n in subg},\n",
    "    node_size = [30 * n.time_left for n in subg],\n",
    "    node_color = [300 * heur(n) / heurmax for n in subg],\n",
    "    alpha = 1.0,\n",
    "    cmap = 'jet'\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for n in nx.dfs_preorder_nodes(g, State(s)):\n",
    "    if vals[n] < valmax:\n",
    "        continue\n",
    "    \n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nx.dfs_preorder_nodes(g, State(s)):\n",
    "    if not n.loaded:\n",
    "        continue\n",
    "    \n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([heur(n) for n in g]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "systems[root_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
